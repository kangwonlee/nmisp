{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kangwonlee/nmisp/blob/numba-cuda/20_probability/25_regression_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example : Linear Regression using PyTorch<br>사례 : PyTorch를 이용한 선형회귀\n",
    "\n",
    "PyTorch is a library specialized in (computational) machine learning originally developed by Meta AI<br>PyTorch 는 Meta AI에서 기원한 (전산) 기계 학습에 특화된 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare data<br>데이터를 준비\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "\n",
    "nr.seed()\n",
    "\n",
    "\n",
    "a = 0.5\n",
    "b = 2.0\n",
    "\n",
    "x_array = np.linspace(0, 5, 100 + 1)\n",
    "y_true = a * x_array + b\n",
    "\n",
    "w_array = nr.normal(0, 0.25, size=x_array.shape)\n",
    "y_measurement = y_true + w_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's plot the data<br>데이터를 한번 그려보자\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(x_array, y_true, label='true')\n",
    "plt.plot(x_array, y_measurement, '.', label='measurement')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Declare the linear model<br>선형 모델을 선언\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "  def __init__(self, in_size=1, out_size=1):\n",
    "    super(LinearRegression, self).__init__()\n",
    "    self.linear = torch.nn.Linear(in_size, out_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate the linear model<br>`LinearRegression` 클래스의 객체를 만듦 (객체는 메모리를 차지할 것임)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = LinearRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It randomly initializes the weight and bias.<br>가중치와 편향은 무작위로 초기화됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = list(custom_model.parameters())\n",
    "w.item(), b.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert `numpy.array` to `float64` `torch.Tensor`<br>`numpy.array` 를 `torch.Tensor`로 변환 (각 원소는 `float64`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor_float64 = torch.from_numpy(x_array)\n",
    "y_tensor_float64 = torch.from_numpy(y_measurement)\n",
    "\n",
    "x_tensor_float64\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert `float64` to `float32`<br>`float64` 를 `float32`로 변환\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor_float32 = x_tensor_float64.float()\n",
    "y_tensor_float32 = y_tensor_float64.float()\n",
    "x_tensor_float32\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert to $n \\times 1$ tensor to match model weight dimension<br>모델 가중치의 차원과 맞추기 위해 $n \\times 1$ 텐서로 변환\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = x_tensor_float32.view(-1, 1)\n",
    "y_tensor = y_tensor_float32.view(-1, 1)\n",
    "x_tensor.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make prediction (using random weight and bias)<br>(무작위 기울기와 절편으로) 예측을 시도해 보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tensor = custom_model(x_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x_array, y_true, y_measurement, y_hat_tensor, y_hat_label):\n",
    "  plt.plot(x_array, y_true, label='true')\n",
    "  plt.plot(x_array, y_measurement, '.', label='measurement')\n",
    "  plt.plot(\n",
    "      x_array, y_hat_tensor.detach().numpy(), '.',\n",
    "      label=y_hat_label\n",
    "  )\n",
    "  plt.legend(loc=0)\n",
    "  plt.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x_array, y_true, y_measurement, y_hat_tensor, 'initial prediction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's use (Stochastic) Gradient Descent for the optimizer<br>최적화 방안으로 (확률적) 경사 하강법을 선택 해 보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(custom_model.parameters(), lr=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mean Square Error will be our loss function.<br>손실 함수로 평균 제곱 오차 (MSE) 를 사용하자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's train the model<br>모델을 학습시켜 보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(y_tensor, x_tensor, model, optimizer, criterion, n_epoch=1000):\n",
    "  cost = []\n",
    "  w_list = []\n",
    "  b_list = []\n",
    "\n",
    "  # to save CI time\n",
    "  if os.getenv('CI', False):\n",
    "    n_epoch = 1\n",
    "\n",
    "  for epoch in range(n_epoch):\n",
    "    # Originally, we would feed each data point to the SGD optimizer.\n",
    "    # Here we are feeding the whole batch of the data, instead. ;)\n",
    "    optimizer.zero_grad()\n",
    "    yhat = model(x_tensor)\n",
    "    loss = criterion(yhat, y_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    cost.append(loss.item())\n",
    "\n",
    "    w_param, b_param = list(model.parameters())\n",
    "    w_list.append(w_param.item())\n",
    "    b_list.append(b_param.item())\n",
    "  # end epoch loop\n",
    "\n",
    "  return cost, w_list, b_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cost_list, w_list, b_list = train(\n",
    "    y_tensor, x_tensor,\n",
    "    custom_model, optimizer, criterion\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How fast does the loss function decreases?<br>손실함수가 얼마 정도 빨리 감소하는가?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(cost_list, '.')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_trained_tensor = custom_model(x_tensor)\n",
    "plot(x_array, y_true, y_measurement, y_hat_trained_tensor, 'after training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cost_surface(\n",
    "    w_range:int, b_range:int,\n",
    "    X:torch.tensor, Y:torch.tensor,\n",
    "    n_samples:int=31,\n",
    "):\n",
    "  # inspired by\n",
    "  # https://www.coursera.org/learn/deep-neural-networks-with-pytorch/\n",
    "\n",
    "  w_vec = np.linspace(0, w_range, n_samples)\n",
    "  b_vec = np.linspace(0, b_range, n_samples)\n",
    "\n",
    "  w_grid, b_grid = np.meshgrid(w_vec, b_vec)\n",
    "\n",
    "  x = X.numpy().reshape(1, -1)\n",
    "  y = Y.numpy().reshape(1, -1)\n",
    "\n",
    "  x_one = np.vstack([\n",
    "    x,\n",
    "    np.ones_like(x)\n",
    "  ])\n",
    "\n",
    "  w_flat = w_grid.flatten()\n",
    "  b_flat = b_grid.flatten()\n",
    "  wb = np.column_stack([w_flat, b_flat])\n",
    "\n",
    "  assert wb.shape[-1] == x_one.shape[0], (\n",
    "      '\\n'\n",
    "      f\"w_flat.shape = {w_flat.shape}\\n\"\n",
    "      f\"wb.shape = {wb.shape}\\n\"\n",
    "      f\"x_one.shape = {x_one.shape}\\n\"\n",
    "  )\n",
    "  yhat = wb @ x_one\n",
    "\n",
    "  ones_y = np.ones((len(w_flat), 1))\n",
    "\n",
    "  # using numpy broadcasting along the first dimension\n",
    "  # yhat [pq, n]\n",
    "  # y[1, n]\n",
    "  error = yhat - y\n",
    "  z_flat = np.mean(error**2, axis=1)\n",
    "\n",
    "  Z = z_flat.reshape(*w_grid.shape)\n",
    "\n",
    "  return w_grid, b_grid, Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_surf(X:torch.tensor, Y:torch.tensor, w_range:int=2, b_range:int=5):\n",
    "  w_grid, b_grid, Z = calc_cost_surface(w_range, b_range, X, Y)\n",
    "  _, ax = plt.subplots(\n",
    "      1, 1,\n",
    "      subplot_kw={'projection':'3d'},\n",
    "      figsize=(16, 9),\n",
    "  )\n",
    "  ax.plot_surface(w_grid, b_grid, Z, alpha=0.5)\n",
    "  ax.set_xlabel('w')\n",
    "  ax.set_ylabel('b')\n",
    "  ax.set_zlabel('l(w,b)')\n",
    "  ax.grid(True)\n",
    "\n",
    "  return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_cost_surf(x_tensor, y_tensor)\n",
    "ax.plot(w_list, b_list, cost_list, '.');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Bell<br>마지막 종\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackoverfow.com/a/24634221\n",
    "import os\n",
    "os.system(\"printf '\\a'\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}