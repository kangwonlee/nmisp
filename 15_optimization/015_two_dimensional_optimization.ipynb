{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kangwonlee/nmisp/blob/lecture-idea/15_optimization/015_two_dimensional_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as so\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref : https://matplotlib.org/stable/gallery/\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2차원 최적화<br>Two dimensional optimizations\n",
    "\n",
    "다음과 같은 비용 함수를 생각해 보자.<br>Let's think about a cost function as follows.\n",
    "\n",
    "$$\n",
    "C(x_0, x_1) = \\frac{x_0^2}{2^2} + \\frac{x_1^2}{1^2}\n",
    "$$\n",
    "\n",
    "파이썬으로는 다음과 같이 구현할 수 있을 것이다.<br>We may implement in python as follows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(x:np.ndarray, a:float=2, b:float=1) -> float:\n",
    "    x0 = x[0]\n",
    "    x1 = x[1]\n",
    "    \n",
    "    return (x0 * x0) / (a * a) + (x1 * x1) / (b * b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각화 해 보자.<br>Let's visualize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost():\n",
    "    # ref : https://matplotlib.org/stable/gallery/\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    ax2 = plt.subplot(1, 2, 2, projection=\"3d\")\n",
    "\n",
    "    x = np.linspace(-4, 4)\n",
    "    y = np.linspace(-2, 2)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    Z = c((X, Y))\n",
    "\n",
    "    cset = ax1.contour(X, Y, Z, cmap=cm.coolwarm)\n",
    "\n",
    "    surf = ax2.plot_surface(X, Y, Z, antialiased=True, cmap=cm.viridis, alpha=0.5)\n",
    "    fig.colorbar(surf)\n",
    "\n",
    "    return ax1, ax2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간 과정의 그래프를 그려 주는 비용 함수를 선언<br>Declare another cost function that will plot intermediate results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost_with_plot(a=2, b=1, b_triangle=True):\n",
    "\n",
    "    x0_history = []\n",
    "    x1_history = []\n",
    "    c_history = []\n",
    "\n",
    "    def cost_with_plot(x, a=a, b=b):\n",
    "        '''\n",
    "        이런 함수를 클로져 라고 부름. 다른 함수의 내부 함수이면서 해당 함수의 반환값.\n",
    "        This is a closuer; an internal function being a return value\n",
    "        '''\n",
    "        ax1, ax2 = plot_cost()\n",
    "\n",
    "        result = c(x)\n",
    "\n",
    "        x0_history.append(x[0])\n",
    "        x1_history.append(x[1])\n",
    "        c_history.append(result)\n",
    "\n",
    "        ax1.plot(x0_history, x1_history, '.')\n",
    "        ax2.plot(x0_history, x1_history, c_history, '.')\n",
    "\n",
    "        if b_triangle and (3 <= len(x0_history)):\n",
    "            ax1.plot(\n",
    "                x0_history[-3:]+[x0_history[-3]],\n",
    "                x1_history[-3:]+[x1_history[-3]],\n",
    "                '-'\n",
    "            )\n",
    "            ax2.plot(\n",
    "                x0_history[-3:]+[x0_history[-3]],\n",
    "                x1_history[-3:]+[x1_history[-3]],\n",
    "                c_history[-3:]+[c_history[-3]],\n",
    "                '-'\n",
    "            )\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        return result\n",
    "\n",
    "    return cost_with_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_with_plot = get_cost_with_plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nelder-Mead 법\n",
    "ref : [[0]](https://en.wikipedia.org/wiki/Nelder-Mead_method)<br>\n",
    "Nelder-Mead 법은 비용함수의 독립변수가 $n$ 차원인 경우, $n+1$ 개의 점으로 이루어진 **simplex**를 이용한다.<br>\n",
    "If the independend variables of the cost function is $n$-dimensional, the Nelder-Mead method uses a **simplex** of $n+1$ vertices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nm_result = so.minimize(cost_with_plot, [3.0, 1.0], method=\"Nelder-Mead\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton-CG 법\n",
    "비용함수를 각각 $x_0$, $x_1$에 대해 편미분 해 보자.<br>Let's get the partial derivatives of the cost function over $x_0$ and $x_1$.\n",
    "$$\n",
    "C(x_0, x_1) = \\frac{x_0^2}{2^2} + \\frac{x_1^2}{1^2} \\\\\n",
    "\\frac{\\partial C}{\\partial x_0} = 2 \\cdot \\frac{x_0}{2^2} \\\\\n",
    "\\frac{\\partial C}{\\partial x_1} = 2 \\cdot \\frac{x_1}{1^2}\n",
    "$$\n",
    "파이썬으로는 다음과 같이 구현할 수 있을 것이다.<br>One may implement in python as follows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian(x, a=2, b=1):\n",
    "    x0 = x[0]\n",
    "    x1 = x[1]\n",
    "    return np.array((2 * x0 / (a*a), 2 * x1 / (b*b),))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화에도 기울기를 사용할 수 있다.<br>We can also use the slopes in the optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_with_plot = get_cost_with_plot(b_triangle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin_newton = so.minimize(cost_with_plot, [3.0, 1.0], jac=jacobian, method=\"newton-cg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin_newton\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}